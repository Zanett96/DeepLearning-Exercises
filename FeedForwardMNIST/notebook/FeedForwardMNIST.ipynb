{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST handwritten digit problem\n",
    "This is meant to be a simple example of how we can tackle the MNIST dataset using pytorch. This is **not** meant to be some *state-of-art* implementation, but a possible help for students looking for easy implementations. \n",
    "Here we are facing a supervised classification problem, whereas our input (handwritten digits) must be correctly classified as a number between 0 and 9. We'll first load the traning and testing samples from the MNIST dataset avaible from tochvision. Then, the feed-forward network must be trained using a proper cross-validation scheme to avoid overfitting. We'll need o find a good set of hyperparameters that return us a good accuracy. \n",
    "\n",
    "We start by importing some libraries that will come in handy later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import scipy.io as io\n",
    "import random\n",
    "import torchvision\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import OrderedDict\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "\n",
    "np.random.seed(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the input\n",
    "We begin by locally download the MNIST dataset from torchvision. We are considering batches of images to speed up the trainining and testing process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Size if the batch of images\n",
    "batch_size = 100\n",
    "\n",
    "## Download batch of images and labels from MNIST dataset\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "                        torchvision.datasets.MNIST('../data', train=True, download=True,\n",
    "                           transform=torchvision.transforms.Compose([\n",
    "                           torchvision.transforms.ToTensor(),\n",
    "                           torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ])),\n",
    "        batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "                        torchvision.datasets.MNIST('../data', train=False, \n",
    "                           transform=torchvision.transforms.Compose([\n",
    "                           torchvision.transforms.ToTensor(),\n",
    "                           torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ])),\n",
    "        batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've download the data, we can start by understand our input images. Those consist of tensors of 784 pixels (28x28). Let's start by visualizing a random image of a batch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(iter(train_loader))\n",
    "\n",
    "i = np.random.randint(0,99)\n",
    "## Analize the inputs by plotting one image\n",
    "\n",
    "img = images[i]\n",
    "print(\"label: \", int(labels[i]))\n",
    "img = np.array(img, dtype='float')\n",
    "pixels = img.reshape((28, 28))\n",
    "plt.imshow(pixels, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wonderful! Now let’s try displaying a full batch of images!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Display one batch of images\n",
    "figure = plt.figure()\n",
    "num_of_images = batch_size\n",
    "\n",
    "for index in range(1, num_of_images):\n",
    "    plt.subplot(10, 10, index)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(images[index].reshape((28, 28)).numpy().squeeze(), cmap='gray_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The network architecture\n",
    "It’s now time to create our neural network. The idea is to implement a simple supervised feed-forward network which trough back-propagation will adjust its state in order to define which digit our input image represent. We have seen that our inputs are composed by 784 values. Therefore, it’s obvious to pick the dimension of our input layer accordingly. The outer layer has to represent which digit we gave in input, thus we choose the dimension of 10 neurons. As for the activation function in the hidden layers, we'll use *ReLU* over *sigmoid* since it achieves a better representation trough sparsity. *ReLU* is also less likely to suffer from gradient vanishing, but with two layer it’s not a real problem anyway. The last layer goes trough a *Softmax* function. The *Softmax* function calculates the probabilities distribution of the value of the image, over the 10 different outputs. The range will be from 0 to 1 and the sum of all probabilities will be equal to 1. This is going to be helpful when we’re going to examine which probabilities has every single digit over an image. The loss criterion used is the *Cross Entropy* loss function. This loss function measures the performance of a classification model whose output is a probability value between 0 and 1, as in our case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fully connected NN with 2 hidden layers using ReLU\n",
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self, Ni, Nh1, Nh2, No):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=Ni, out_features=Nh1)\n",
    "        self.fc2 = nn.Linear(Nh1, Nh2)\n",
    "        self.fc3 = nn.Linear(Nh2, No)\n",
    "        \n",
    "        self.soft = nn.LogSoftmax(dim=1)\n",
    "        self.act = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x): \n",
    "        x = self.act(self.fc1(x))\n",
    "        x = self.act(self.fc2(x))     \n",
    "        out = self.soft(self.fc3(x))\n",
    "        return out\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A slightly different implementation of the network add *dropout* on the hidden layers. Trough dropout, we randomly drop a unit and all its connections. The drop happens with a fixed probability of 0.5. The implementation of dropout doesn’t change the network architecture, but instead set to zero the output of the node we chose to drop. This implementation perform slightly better than the standard implementation, thus is suggested to utilize. Try by yourself how the performance change by implementing both!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fully connected NN with 2 hidden layers using ReLU and dropout on hidden layers\n",
    "class Net_dropout(nn.Module):\n",
    "    \n",
    "    def __init__(self, Ni, Nh1, Nh2, No):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.fc1 = nn.Linear(in_features=Ni, out_features=Nh1)\n",
    "        self.fc2 = nn.Linear(Nh1, Nh2)\n",
    "        self.fc3 = nn.Linear(Nh2, No)\n",
    "        self.soft = nn.LogSoftmax(dim=1)\n",
    "        self.act = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x): \n",
    "        \n",
    "        x = self.dropout(self.act(self.fc1(x)))\n",
    "        x = self.dropout(self.act(self.fc2(x)))        \n",
    "        out = self.soft(self.fc3(x))\n",
    "        \n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is used later on to display the input images and the probabilities of the activations of the 10 output layers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Print the digit and the probabilities of activation in the last layer\n",
    "def view_classify(img, ps):\n",
    "    ps = ps.data.numpy().squeeze()\n",
    "    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n",
    "    ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\n",
    "    ax1.axis('off')\n",
    "    ax2.barh(np.arange(10), ps)\n",
    "    ax2.set_aspect(0.1)\n",
    "    ax2.set_yticks(np.arange(10))\n",
    "    ax2.set_yticklabels(np.arange(10))\n",
    "    ax2.set_title('Class Probability')\n",
    "    ax2.set_xlim(0, 1.1)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and testing the network\n",
    "Let's now define the training procedure! During the train, images get passed trough the network during the forward propagation. Then the loss between the prediction and the correct labels gets calculated, and we do a back-propagation of the error. Finally, we update the weights of our network. During the train, we calculate the losses of the training set, to monitor the learning of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Define the loss function used by the network\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "train_loss, training_loss_mean = [], []\n",
    "\n",
    "## Define the training procedure\n",
    "def net_train(num_epochs, lr, model, train_loader):\n",
    "    \n",
    "    ## Define a SGD optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            \n",
    "            #Reshape the array\n",
    "            image = images.view(images.shape[0], -1)\n",
    "           \n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "            ## forward propagation\n",
    "            output = model(image)\n",
    "            \n",
    "            ## loss calculation\n",
    "            loss = loss_fn(output, labels)\n",
    "        \n",
    "            ## backward propagation\n",
    "            loss.backward()\n",
    "        \n",
    "            ## weight optimization\n",
    "            optimizer.step()\n",
    "            \n",
    "            ## store the loss on the training\n",
    "            train_loss.append(loss.item())\n",
    "            training_loss_mean.append(np.mean(train_loss))\n",
    "    \n",
    "        print (\"Epoch: \", epoch, \"Training Loss: \", np.mean(train_loss))\n",
    "        \n",
    "    return np.mean(train_loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we have the function used for testing our data. This return us the % accuracy over the samples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Try the model on the unseen test set\n",
    "test_loss, test_loss_avg = [], []\n",
    "\n",
    "def net_test(model,  test_loader):\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        total, correct = 0, 0\n",
    "        c = 0\n",
    "        \n",
    "        for (images, labels) in test_loader:\n",
    "            \n",
    "            #Reshape the array\n",
    "            image = images.view(images.shape[0], -1) \n",
    "            \n",
    "            for i in range (len(labels)):\n",
    "                \n",
    "                output = model(image)\n",
    "                \n",
    "                loss = loss_fn(output, labels.squeeze())\n",
    "                \n",
    "                test_loss.append(loss.item())\n",
    "                test_loss_avg.append(np.mean(test_loss))\n",
    "                \n",
    "                _, predicted = torch.max(output.data, 1)\n",
    "                correct += (predicted.data[i].item() == labels.data[i].item())\n",
    "                \n",
    "            total += labels.size(0)\n",
    "            \n",
    "    #Print the accuracy of the network\n",
    "    print('Accuracy of the network on the ', total, ' test images: {} %'.format(100*correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters research\n",
    "As probably many of the readers of this notebook know, an important part of creating a Neural network is the research of the best hyperparameters. Here we choose to use a *random search* to search for various configurations of the model by varying the learning rate and the number of epochs. In the end we choose the ones that implies the minimum training error. Just for the sake of testing, we are going to consider 200 neurons in the hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## numbers of conbinations of hyperparameters to try\n",
    "num_iters = 10\n",
    "maximum = 0\n",
    "\n",
    "loss_store, lr_store, epoch_store = [], [], []\n",
    "Ni = 784\n",
    "Nh1 = 200\n",
    "Nh2 = 200\n",
    "No = 10\n",
    "\n",
    "best_lr, best_epochs = 0,0 \n",
    "\n",
    "## Random search - Long time to process, excute only when researching hyperparameters!!!\n",
    "for i in range(num_iters):   \n",
    "    #Initialize the network\n",
    "    model = Net(Ni, Nh1, Nh2, No)\n",
    "    \n",
    "    #Set random parameters\n",
    "    rand_lr = random.randint(1,5)*(10**(-random.randint(2,6)))\n",
    "    rand_epoch = (random.randint(2,20))\n",
    "    print(\"iteration: \", i, \" lr: \", rand_lr, \"and #epoch: \", rand_epoch)\n",
    "    \n",
    "    #Compute the training\n",
    "    loss = net_train(rand_epoch, rand_lr, model, train_loader)\n",
    "    \n",
    "    ##Store the parameters\n",
    "    loss_store.append(loss)\n",
    "    lr_store.append(rand_lr)\n",
    "    epoch_store.append(rand_epoch)\n",
    "    \n",
    "    ## Update the best parameters\n",
    "    if(i == 0): maximum = loss\n",
    "    elif (loss < maximum):\n",
    "        best_lr = rand_lr\n",
    "        best_epochs = rand_epoch\n",
    "        maximum = loss\n",
    "        print(\"The best loss so far is: \", maximum, \" with lr: \", rand_lr, \"and #epoch: \", rand_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how our random search parameters turned out on a nice plot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Plot random search configuration\n",
    "plt.close('all')\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.scatter(lr_store, epoch_store)\n",
    "plt.xlabel('Lr')\n",
    "plt.ylabel('epoch')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've found some nice values of lr and epochs, let's compute the actual training! In particular, we consider the network using dropout with 1000 neurons in the first hidden layer and 800 neurons in the second hidden layer. We can also compute the train without using dropout by using *Net()* instead of *Net_dropout()*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Train on network with dropout enabled\n",
    "Nh1 = 1000\n",
    "Nh2 = 800\n",
    "model = Net_dropout(Ni, Nh1, Nh2, No)\n",
    "net_train(best_epochs, best_lr, model, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train the network without using dropout\n",
    "#Nh1 = 200\n",
    "#Nh2 = 200\n",
    "#model = Net(Ni, Nh1, Nh2, No)\n",
    "#net_train(best_epochs, best_lr, model, train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's time to check how our model perform on unseen data. Trough the call of the *net_test()* function we'll know what the accuracy of our network actually is. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test the network\n",
    "net_test(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Study the output\n",
    "We have finally trained and tested our network. What now? \n",
    "Well, since this is a student-like approach to the problem, we are going to go deeper into the actual \"stuff\" our network is doing. Let's start by analizing the output. We have defined the use of a *Softmax* function in the last layer, so we actually expect to obtain some probabilities on the neurons in the last layer. Let's display now some input images with the corresponding output layer. Particular attention must be given to the images our network failed to correctly classify. Look at how the probabilities are actually describing what our model think is the correct digit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (80, 100):\n",
    "    #resize\n",
    "    img = images[i].view(1, 784)\n",
    "    \n",
    "    # Compute the \n",
    "    with torch.no_grad():\n",
    "        ps = model(img)\n",
    "    # To get probabilities we compute exp of the output \n",
    "    ps = torch.exp(ps)\n",
    "    probab = list(ps.numpy()[0])\n",
    "    \n",
    "    #Print results\n",
    "    print(\"Predicted Digit =\", probab.index(max(probab)), \" True digit= \", int(labels[i]))\n",
    "    view_classify(img.view(1, 28, 28), ps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another interesting thing to plot are the weights of our model. Since this is a simple network, we can actually linearly combine the weights of the neurons to extract some \"features\" which are encoded by that specific neuron. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Return shapes of the parameters of our net\n",
    "for name, param in model.named_parameters():\n",
    "    print(name, '\\t\\t', param.shape)\n",
    "    \n",
    "#Get the network parameters\n",
    "params = list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the weights matrix of the first 50 connections   \n",
    "for i in range (1,50):\n",
    "    img = params[0][i].view(1, 784)\n",
    "    img = img.detach().numpy()\n",
    "    pixels = img.reshape((28, 28))  \n",
    "    plt.subplot(5, 10, i)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(pixels.squeeze(), cmap='gray_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute the product between W1 and W2j weights matrix and plot\n",
    "for i in range (1,40): \n",
    "    mul = params[2][i].matmul(params[0])\n",
    "    img = mul.view(1, 784)\n",
    "    img = img.detach().numpy()\n",
    "    pixels = img.reshape((28, 28)) \n",
    "    plt.subplot(4, 10, i)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(pixels, cmap='gray_r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mul0 = params[2].matmul(params[0])\n",
    "\n",
    "#Compute the product between W1,W2 and W3j weights matrix and plot\n",
    "for i in range (1,10): \n",
    "    mul = params[4][i].matmul(mul0)\n",
    "    img = mul.view(1, 784)\n",
    "    img = img.detach().numpy()\n",
    "    pixels = img.reshape((28, 28))\n",
    "    plt.subplot(1, 10, i)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(pixels.squeeze(), cmap='gray_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
